{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading in data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in data. We'll store our data in dataframe called 'df'.\n",
    "\n",
    "df = pd.read_csv('Alignment-HitTable.csv', header = None)\n",
    "df.columns = ['query acc.verr', 'subject acc.ver', '% identity', 'alignment length', 'mismatches', \n",
    "             'gap opens', 'q. start', 'q. end', 's. start', 's. end', 'evalue', 'bit score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part A (25 pts)\n",
    "\n",
    "## In this final notebook, we'll be predicting 'bit_score' from some of the columns in the data.\n",
    "## Create a feature dataframe called 'X' with the columns: ['% identity',  'mismatches', 'gap opens', 'q. start', 's. start'].\n",
    "## Store the target 'y' with the bit scores.\n",
    "\n",
    "X = df[['% identity',  'mismatches', \n",
    "             'gap opens', 'q. start', 's. start']]\n",
    "y = df['bit score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part B (15 pts)\n",
    "\n",
    "### Use the Standard Scaler from the sklearn.preprocessing library to normalize the data.\n",
    "## Store the transformed X data in a variable called 'X_transformed'.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_transformed = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part C (25 pts)\n",
    "\n",
    "## Predict the bit score by fitting a linear regression model. Store the predicted bit scores in\n",
    "## a variable called 'lin_pred'. Get the score in a variable called 'lin_score'. \n",
    "## Store the linear regression coefficients in a variable called 'coef'.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_transformed, y)\n",
    "score = linreg.score(X_transformed, y)\n",
    "lin_pred = linreg.predict(X_transformed)\n",
    "coef = linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part D (35 pts)\n",
    "\n",
    "## Split the data into a train/test set using the sklearn train/test split with a random state of 42.\n",
    "## Predict the bit score by fitting a neural network MP regression model. \n",
    "## Use a random state of 42, 3 hidden layers each of size 50, and a 'sgd' solver.\n",
    "## Store the predicted bit scores of the test set in a variable called 'nn_pred'. \n",
    "## Get the score on the test set in a variable called 'nn_score'. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, random_state = 42)\n",
    "nn = MLPRegressor(random_state=42, solver = 'sgd', hidden_layer_sizes = (50,3)).fit(X_train, y_train)\n",
    "nn_pred = nn.predict(X_test)\n",
    "nn_score = nn.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
